{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "from xml.etree.ElementTree import parse\n",
    "import normalized_stations\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OSMFILE = \"bs_as_subway.osm\"\n",
    "actual_stations = []\n",
    "decoded_stations = []\n",
    "final_normalization = []\n",
    "# tokenized_stations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_stations(k_tags, v_tags):\n",
    "    if \"subway\" in k_tags:\n",
    "        actual_stations.append(v_tags[0])\n",
    "        \n",
    "        \n",
    "def process_every_node(itero):\n",
    "    k_tags = []\n",
    "    v_tags = []\n",
    "    for tag in itero:\n",
    "        k_tags.append(tag.attrib['k']) \n",
    "        v_tags.append(tag.attrib['v'])\n",
    "    extract_stations(k_tags, v_tags)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_and_collect_nodes(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    doc = ET.iterparse(osm_file, events=(\"start\",\"end\"))\n",
    "    for event, elem in doc:\n",
    "        if event == \"start\" and elem.tag == \"node\":\n",
    "            process_every_node(elem.iter(\"tag\"))\n",
    "        elif event == \"end\":\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ParseError",
     "evalue": "unclosed token: line 41841, column 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<string>\"\u001b[0;36m, line \u001b[0;32munknown\u001b[0m\n\u001b[0;31mParseError\u001b[0m\u001b[0;31m:\u001b[0m unclosed token: line 41841, column 1\n"
     ]
    }
   ],
   "source": [
    "parse_and_collect_nodes(OSMFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for station in actual_stations:\n",
    "#    print station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def to_ascii_actual_stations():\n",
    "    for station in actual_stations:\n",
    "        decoded_stations.append(unidecode(station))\n",
    "        \n",
    "def tobe_normalized_stations():\n",
    "    for station in decoded_stations:\n",
    "        if station not in normalized_stations.all_stations():\n",
    "            final_normalization.append(station)\n",
    "\n",
    "to_ascii_actual_stations()\n",
    "tobe_normalized_stations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for norm_station in final_normalization:\n",
    "#    print norm_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plaza   Virreyes   Eva Peron\n",
      "Avenida Plata\n",
      "Entre Rios   Rodolfo Walsh\n",
      "Independencia  \n",
      "Independencia  \n",
      "General Urquiza\n",
      "Tribunales\n",
      "Callao  \n",
      "Pueyrredon  \n",
      "Inclan Mezquita Al Ahmad\n",
      "Pasteur   AMIA\n",
      "Medrano Almagro\n",
      "Malabia   Osvaldo Pugliese\n",
      "Federico Lacroze\n",
      "Tronador   Villa Ortuzar\n",
      " Incas   Parque Chas\n"
     ]
    }
   ],
   "source": [
    "tokens_to_ignore = [\" de \", \" los \", \"-\", \" La \", \"Los \", \"los\", \"\\(E\\)\", \"\\(C\\)\", \"\\(D\\)\"]\n",
    "## split each station name in final_normalization in tokens ignoring the ones in tokens_to_ignore\n",
    "pattern = '|'.join(tokens_to_ignore)\n",
    "# print pattern\n",
    "\n",
    "\n",
    "def split_and_review():\n",
    "    tokenized_stations = []\n",
    "    for norm_station in final_normalization:        \n",
    "        tokeners = re.sub(pattern, ' ', norm_station)\n",
    "        print tokeners\n",
    "        # tokenized_stations.append(tokeners)\n",
    "    \n",
    "    # tokens = station.split()\n",
    "split_and_review()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for station in tokenized_stations:\n",
    "#    print station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n"
     ]
    }
   ],
   "source": [
    "cont = 0\n",
    "for station in normalized_stations.all_stations():\n",
    "    cont = cont + 1\n",
    "print cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    }
   ],
   "source": [
    "cont = 0\n",
    "for station in actual_stations:\n",
    "    cont = cont + 1\n",
    "print cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for station in actual_stations:\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
